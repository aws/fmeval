{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/schwobel/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import fmeval\n",
    "import sagemaker\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we evaluate a few different models on the question answering task and plot the results in order to compare their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to test the endpoint: \n",
    "# 1/ we test that the endpoint exists and \n",
    "# 2/ that it \n",
    "def test_endpoint(predictor):\n",
    "    prompt = \"London is the capital of\"\n",
    "    payload = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.9,\n",
    "            \"temperature\": 0.8,\n",
    "            \"max_new_tokens\": 1024,\n",
    "            \"decoder_input_details\" : True,\n",
    "            \"details\" : True\n",
    "        },\n",
    "    }\n",
    "    response = predictor.predict(payload)\n",
    "    print(f'Query successful. Prompt: {prompt} ... Model response: {response[0][\"generated_text\"]}')\n",
    "    output_format ='[0].generated_text' \n",
    "    return output_format \n",
    "\n",
    "# function to get existing endpoint for a model or deploy a new one if none exists \n",
    "def get_endpoint(model_id, model_version, endpoint_name=\"\"):\n",
    "    print(\"Using existing endpoint.\")\n",
    "    predictor = sagemaker.predictor.Predictor(\n",
    "        endpoint_name=endpoint_name,\n",
    "        serializer=sagemaker.serializers.JSONSerializer(),\n",
    "        deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "    )\n",
    "    try:\n",
    "        output_format = test_endpoint(predictor)\n",
    "    except: \n",
    "        print(\"No working endpoint found. Deploying a new one.\")\n",
    "        my_model = JumpStartModel(model_id=model_id, model_version=model_version)\n",
    "        predictor = my_model.deploy()\n",
    "        endpoint_name = predictor.endpoint_name\n",
    "        output_format = test_endpoint(predictor)\n",
    "    return endpoint_name, predictor, output_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing endpoint.\n",
      "Query successful. Prompt: London is the capital of ... Model response:  the UK and a beautiful city. It is the most important political, financial, cultural, and educational centre in the country. The city has been at the centre of many revolutions, from the Roman invasion of 55 BC to the English Revolution in the 17th century. It is also home to one of the most popular and famous tourist attractions in the world: Buckingham Palace.\n",
      "There are many things to do in London. You can visit its famous tourist attractions, such as the Tower of London, Buckingham Palace, Big Ben, and the London Eye. You can also enjoy the many museums and galleries in the city. If you are looking for some fun things to do in London, here are some ideas:\n",
      "Visit the London Eye\n",
      "The London Eye is the world’s tallest Ferris wheel. It offers spectacular views of London and is a great place to visit if you are looking for a fun thing to do in London. The London Eye is located in the South Bank district of London. It is one of the most popular tourist attractions in the city. The London Eye is a large Ferris wheel that was built in 1999. It is 135 metres tall and can hold up to 800 people. The London Eye is a great place to see the city from above. You can also see the Thames River and the Houses of Parliament from the London Eye. The London Eye is open from 10 am to 11 pm every day. Admission is free.\n",
      "Visit the Tower of London\n",
      "The Tower of London is a castle located in the City of London. It is one of the most famous tourist attractions in London. The Tower of London was built in the 11th century and has been used as a prison, a royal palace, and a military fortification. Today, the Tower of London is a popular tourist attraction. You can visit the Tower of London to see the Crown Jewels, the Royal Mint, and the Traitors’ Gate. You can also take a guided tour of the Tower of London.\n",
      "Visit Buckingham Palace\n",
      "Buckingham Palace is the official residence of the British monarch. It is located in the City of Westminster, London. The palace is open to the public for tours. The palace is a beautiful building with ornate interiors. The palace is the centre of British government and is the most famous tourist attraction in the country.\n",
      "Take a walk down the South Bank\n",
      "The South Bank is a stretch of land along the Thames River in the South Bank district of London. The South Bank is a popular tourist attraction in London. It is a great place to walk, run, or bike. The South Bank is also home to many cultural institutions, such as the National Theatre and the Tate Modern.\n",
      "Explore the museums and galleries\n",
      "London is home to many museums and galleries. There are many different types of museums and galleries in London. Some of the most popular museums and galleries in London include the British Museum, the Natural History Museum, the Science Museum, the Tate Modern, the Victoria and Albert Museum, and the National Portrait Gallery.\n",
      "Watch a play or a musical\n",
      "London is home to many theatres and performance venues. You can watch a play or a musical at one of the many theatres in London. Some of the most popular theatres in London include the West End Theatre District, the National Theatre, and the Old Vic Theatre. You can also watch a musical at the Royal Albert Hall.\n",
      "Go shopping\n",
      "London is a great place to go shopping. You can find many different types of shops in London. Some of the most popular shops in London include Selfridges, Harrods, and Fortnum & Mason. You can also find many smaller boutiques and shops in London.\n",
      "Try some of the local food\n",
      "London is a great place to eat. You can find many different types of food in London. Some of the most popular types of food in London include English food, Indian food, and Chinese food. You can also find many different types of fast food in London.\n",
      "Go to a concert or a festival\n",
      "London is home to many different types of concerts and festivals. Some of the most popular concerts and festivals in London include the London Jazz Festival, the London Symphony Orchestra, and the Royal Opera House. You can also find many different types of music and arts festivals in London.\n",
      "Visit a park or a garden\n",
      "London is home to many different parks and gardens. Some of the most popular parks and gardens in London include Hyde Park, Regent’s Park, and St. James’s Park. You can also find many different types of gardens in London. Some of the most popular gardens in London include the Royal Botanic Gardens, Kew Gardens, and Chelsea Physic Garden.\n",
      "Go to the theatre or the ballet\n",
      "London is home to many different types of theatre and ballet companies. Some of the most popular theatre and ballet companies in London include the Royal Shakespeare Company, the Royal Opera House, and the National Ballet of England. You can also find many different types of theatre and ballet companies in London.\n"
     ]
    }
   ],
   "source": [
    "model_id_base, model_version_base, endpoint_name_base = \"huggingface-llm-falcon-7b-bf16\" , \"*\", \"hf-llm-falcon-7b-bf16-2024-03-21-12-51-01-854\"\n",
    "endpoint_name_base, predictor_base, output_format_base = get_endpoint(model_id_base, model_version_base, endpoint_name_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing endpoint.\n",
      "Query successful. Prompt: London is the capital of ... Model response:  England, a bustling city with a lot to offer. It's renowned for its shopping, entertainment, history and culture, but it also has a lot of green spaces and parks. There's a lot of art and museums in London, as well as great restaurants, theatres and cinema. It's also home to a diverse range of people, from different cultures and backgrounds, which contributes to its vibrant atmosphere.\n",
      "If you're looking for an exciting new city to explore, London is the place. It's famous for its bustling shopping scene and its eclectic range of restaurants and bars, with something to suit all tastes and budgets. Whether you're looking to learn about the history, visit some of the world's best museums, or simply relax in a beautiful park, London has it all.\n",
      "London is the capital of England and a bustling city, famous for its shopping, entertainment, history and culture. It has green spaces and parks, art galleries and museums, and a diverse range of people and cultures.\n"
     ]
    }
   ],
   "source": [
    "model_id_instruct, model_version_instruct, endpoint_name_instruct = \"huggingface-llm-falcon-7b-instruct-bf16\" , \"*\", \"hf-llm-falcon-7b-instruct-bf16-2024-03-21-10-15-06-733\"\n",
    "endpoint_name_instruct, predictor_instruct, output_format_instruct = get_endpoint(model_id_instruct, model_version_instruct, endpoint_name=endpoint_name_instruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-21 15:47:18,514\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-03-21 15:47:19,318\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from fmeval.eval_algorithms.qa_accuracy import QAAccuracy, QAAccuracyConfig\n",
    "from fmeval.model_runners.sm_jumpstart_model_runner import JumpStartModelRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    }
   ],
   "source": [
    "model_runner_base = JumpStartModelRunner(\n",
    "    endpoint_name=endpoint_name_base,\n",
    "    model_id=model_id_base,\n",
    "    model_version=model_version_base,\n",
    "    output=output_format_base, # you can test whether this is correct using the \n",
    "    content_template='{\"inputs\": $prompt, \"parameters\": {\"do_sample\": true, \"top_p\": 0.9, \"temperature\": 0.8, \"max_new_tokens\": 1024, \"decoder_input_details\": true,\"details\": true}}',\n",
    ")\n",
    "\n",
    "model_runner_instruct = JumpStartModelRunner(\n",
    "    endpoint_name=endpoint_name_instruct,\n",
    "    model_id=model_id_base,\n",
    "    model_version=model_version_instruct,\n",
    "    output=output_format_instruct, # you can test whether this is correct using the \n",
    "    content_template='{\"inputs\": $prompt, \"parameters\": {\"do_sample\": true, \"top_p\": 0.9, \"temperature\": 0.8, \"max_new_tokens\": 1024, \"decoder_input_details\": true,\"details\": true}}',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is saving the individual examples, no need for now \n",
    "# # helper to configure and run evaluation\n",
    "# def run_eval(model, model_name):\n",
    "#     # configure eval (use default)\n",
    "#     default_config = QAAccuracyConfig()\n",
    "#     qa_eval = QAAccuracy(default_config)\n",
    "#     # configure filepath\n",
    "#     curr_dir = os.getcwd()\n",
    "#     eval_dir = f\"example_results/{model_name}/\"\n",
    "#     eval_results_path = os.path.join(curr_dir, eval_dir) + \"/\"\n",
    "#     os.environ[\"EVAL_RESULTS_PATH\"] = eval_results_path\n",
    "#     if os.path.exists(eval_results_path):\n",
    "#         print(f\"Directory '{eval_results_path}' exists.\")\n",
    "#     else:\n",
    "#         os.mkdir(eval_results_path)\n",
    "#     results = qa_eval.evaluate(model = model, save=True, num_records=5)\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to configure and run evaluation\n",
    "def run_eval(model, model_name):\n",
    "    # configure eval (use default)\n",
    "    default_config = QAAccuracyConfig()\n",
    "    qa_eval = QAAccuracy(default_config)\n",
    "    # configure filepath\n",
    "    results_path = f\"example_results/{model_name}.jsonl\"\n",
    "    results = qa_eval.evaluate(model = model, save=True, num_records=5)\n",
    "    with open(results_path, 'w') as f:\n",
    "        json.dump({'accuracy': results}, f, default=lambda c: c.__dict__)\n",
    "        print(f'Results saved to {results_path}')\n",
    "    return results                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 15:47:38,292\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  return transform_pyarrow.concat(tables)\n",
      "2024-03-21 15:47:46,892\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "2024-03-21 15:47:46,893\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:47:46,894\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "                                                                                                                  \n",
      "\u001b[A\n",
      "\u001b[A2024-03-21 15:47:46,988\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_prompt_column)]\n",
      "2024-03-21 15:47:46,988\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:47:46,989\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "Running: 10.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:   0%|          | 0/45 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(Map(_generate_prompt_column) pid=52077)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52077)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Users/schwobel/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(Map(_generate_prompt_column) pid=52072)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52072)\u001b[0m   if isinstance(items[0], TensorArrayElement):                  \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52072)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52072)\u001b[0m   return items[0]                                               \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52072)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52072)\u001b[0m   if isinstance(items[0], TensorArrayElement):                  \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52072)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52072)\u001b[0m   return items[0]                                               \n",
      "2024-03-21 15:47:49,038\tWARNING util.py:546 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-03-21 15:47:49,042\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[Map(ModelRunnerWrapper)]\n",
      "2024-03-21 15:47:49,043\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:47:49,043\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:47:49,086\tINFO actor_pool_map_operator.py:114 -- Map(ModelRunnerWrapper): Waiting for 9 pool actors to start...\n",
      "\u001b[36m(_MapWorker pid=52150)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52069)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\u001b[32m [repeated 16x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52069)\u001b[0m   if isinstance(items[0], TensorArrayElement):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=52069)\u001b[0m   return items[0]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=52152)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=52150)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=52149)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=52151)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=52152)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\n",
      "2024-03-21 15:48:43,737\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_eval_scores)]\n",
      "2024-03-21 15:48:43,737\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:48:43,738\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "Running: 10.0/10.0 CPU, 0.0/0.0 GPU, 0.01 MiB/512.0 MiB object_store_memory:   0%|          | 0/45 [00:04<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(Map(_generate_eval_scores) pid=52229)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(_generate_eval_scores) pid=52229)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Users/schwobel/Library/Application Support/sagemaker/config.yaml\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 15:48:51,650\tINFO dataset.py:2488 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2024-03-21 15:48:51,652\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:48:51,653\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:48:51,654\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:48:51,753\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:48:51,754\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:48:51,755\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:48:51,851\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:48:51,851\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:48:51,852\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:48:51,943\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:48:51,944\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:48:51,945\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:48:52,022\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:48:52,023\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:48:52,023\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:48:52,104\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-21 15:48:52,105\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:48:52,105\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:48:52,184\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-21 15:48:52,185\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:48:52,186\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:   7%|▋         | 3/45 [00:00<00:03, 13.40it/s]/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "2024-03-21 15:49:52,000\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=104 for stage ReadCustomJSON to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-03-21 15:49:52,000\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 104, each read task output is split into 104 smaller blocks.\n",
      "2024-03-21 15:49:52,001\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCustomJSON] -> LimitOperator[limit=100000]\n",
      "2024-03-21 15:49:52,001\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:49:52,001\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "Running: 1.0/10.0 CPU, 0.0/0.0 GPU, 104.41 MiB/512.0 MiB object_store_memory:   0%|          | 0/1 [00:00<?, ?it/s]2024-03-21 15:51:08,813\tERROR streaming_executor_state.py:476 -- An exception was raised from a task of operator \"ReadCustomJSON->SplitBlocks(104)\". Dataset execution will now abort. To ignore this exception and continue, set DataContext.max_errored_blocks.\n",
      "                                                                                                                   \r"
     ]
    },
    {
     "ename": "RayTaskError(OSError)",
     "evalue": "\u001b[36mray::ReadCustomJSON->SplitBlocks(104)()\u001b[39m (pid=52226, ip=127.0.0.1)\n    for b_out in map_transformer.apply_transform(iter(blocks), ctx):\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 430, in __call__\n    for block in blocks:\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 371, in __call__\n    for data in iter:\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 232, in __call__\n    yield from self._block_fn(input, ctx)\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/planner/plan_read_op.py\", line 82, in do_read\n    yield from read_task()\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/datasource/datasource.py\", line 237, in __call__\n    yield from result\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 308, in read_task_fn\n    yield from read_files(read_paths)\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 279, in read_files\n    for block in read_stream(f, read_path):\n  File \"/Users/schwobel/Documents/code/fmeval_hackathon/fmeval/src/fmeval/data_loaders/json_data_loader.py\", line 95, in _read_stream\n    json_lines_strings = f.readall().decode().strip().split(\"\\n\")\n  File \"pyarrow/io.pxi\", line 514, in pyarrow.lib.NativeFile.readall\n  File \"pyarrow/io.pxi\", line 392, in pyarrow.lib.NativeFile.read\n  File \"pyarrow/io.pxi\", line 409, in pyarrow.lib.NativeFile.read\n  File \"pyarrow/error.pxi\", line 154, in pyarrow.lib.pyarrow_internal_check_status\n  File \"pyarrow/error.pxi\", line 91, in pyarrow.lib.check_status\nOSError: AWS Error NETWORK_CONNECTION during GetObject operation: curlCode: 6, Couldn't resolve host name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(OSError)\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/schwobel/Documents/code/fmeval_fork/fmeval/examples/model-comparison.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/schwobel/Documents/code/fmeval_fork/fmeval/examples/model-comparison.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results_qa_base \u001b[39m=\u001b[39m run_eval(model_runner_base, model_id_base)\n",
      "\u001b[1;32m/Users/schwobel/Documents/code/fmeval_fork/fmeval/examples/model-comparison.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/schwobel/Documents/code/fmeval_fork/fmeval/examples/model-comparison.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# configure filepath\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/schwobel/Documents/code/fmeval_fork/fmeval/examples/model-comparison.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m results_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexample_results/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.jsonl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/schwobel/Documents/code/fmeval_fork/fmeval/examples/model-comparison.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m results \u001b[39m=\u001b[39m qa_eval\u001b[39m.\u001b[39;49mevaluate(model \u001b[39m=\u001b[39;49m model, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, num_records\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/schwobel/Documents/code/fmeval_fork/fmeval/examples/model-comparison.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(results_path, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/schwobel/Documents/code/fmeval_fork/fmeval/examples/model-comparison.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     json\u001b[39m.\u001b[39mdump({\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m: results}, f, default\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m c: c\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/code/fmeval_hackathon/fmeval/src/fmeval/eval_algorithms/qa_accuracy.py:265\u001b[0m, in \u001b[0;36mQAAccuracy.evaluate\u001b[0;34m(self, model, dataset_config, prompt_template, save, num_records)\u001b[0m\n\u001b[1;32m    263\u001b[0m eval_outputs: List[EvalOutput] \u001b[39m=\u001b[39m []\n\u001b[1;32m    264\u001b[0m \u001b[39mfor\u001b[39;00m dataset_config \u001b[39min\u001b[39;00m dataset_configs:\n\u001b[0;32m--> 265\u001b[0m     dataset \u001b[39m=\u001b[39m get_dataset(dataset_config, num_records)\n\u001b[1;32m    266\u001b[0m     validate_dataset(dataset, [DatasetColumns\u001b[39m.\u001b[39mTARGET_OUTPUT\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mname, DatasetColumns\u001b[39m.\u001b[39mMODEL_INPUT\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mname])\n\u001b[1;32m    267\u001b[0m     dataset_prompt_template \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/code/fmeval_hackathon/fmeval/src/fmeval/data_loaders/util.py:52\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(config, num_records)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m# We are using to_pandas, sampling with Pandas dataframe, and then converting back to Ray Dataset to use\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m# Pandas DataFrame's ability to sample deterministically. This is temporary workaround till Ray solves this\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# issue: https://github.com/ray-project/ray/issues/40406\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m count \u001b[39m>\u001b[39m MAX_ROWS_TO_TAKE:\n\u001b[1;32m     48\u001b[0m     \u001b[39m# If count is larger than 100000, we take the first 100000 row, and then sample from that to\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39m# maintain deterministic behaviour. We are using take_batch to get a pandas dataframe of size\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[39m# MAX_ROWS_TO_TAKE when the size of original dataset is greater than MAX_ROWS_TO_TAKE. This is to avoid\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[39m# failures in driver node by pulling too much data.\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     pandas_df \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mtake_batch(batch_size\u001b[39m=\u001b[39;49mMAX_ROWS_TO_TAKE, batch_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpandas\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     pandas_df \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto_pandas()\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/dataset.py:2438\u001b[0m, in \u001b[0;36mDataset.take_batch\u001b[0;34m(self, batch_size, batch_format)\u001b[0m\n\u001b[1;32m   2435\u001b[0m limited_ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlimit(batch_size)\n\u001b[1;32m   2437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2438\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\n\u001b[1;32m   2439\u001b[0m         \u001b[39miter\u001b[39;49m(\n\u001b[1;32m   2440\u001b[0m             limited_ds\u001b[39m.\u001b[39;49miter_batches(\n\u001b[1;32m   2441\u001b[0m                 batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2442\u001b[0m                 prefetch_batches\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2443\u001b[0m                 batch_format\u001b[39m=\u001b[39;49mbatch_format,\n\u001b[1;32m   2444\u001b[0m             )\n\u001b[1;32m   2445\u001b[0m         )\n\u001b[1;32m   2446\u001b[0m     )\n\u001b[1;32m   2447\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   2448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe dataset is empty.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/iterator.py:164\u001b[0m, in \u001b[0;36mDataIterator.iter_batches.<locals>._create_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m    160\u001b[0m \u001b[39m# Iterate through the dataset from the start each time\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39m# _iterator_gen is called.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m# This allows multiple iterations of the dataset without\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m# needing to explicitly call `iter_batches()` multiple times.\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m block_iterator, stats, blocks_owned_by_consumer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_to_block_iterator()\n\u001b[1;32m    166\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\n\u001b[1;32m    167\u001b[0m     iter_batches(\n\u001b[1;32m    168\u001b[0m         block_iterator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m )\n\u001b[1;32m    182\u001b[0m dataset_tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_dataset_tag()\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/iterator/iterator_impl.py:33\u001b[0m, in \u001b[0;36mDataIteratorImpl._to_block_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_block_iterator\u001b[39m(\n\u001b[1;32m     26\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     27\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mbool\u001b[39m,\n\u001b[1;32m     31\u001b[0m ]:\n\u001b[1;32m     32\u001b[0m     ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_dataset\n\u001b[0;32m---> 33\u001b[0m     block_iterator, stats, executor \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39;49m_plan\u001b[39m.\u001b[39;49mexecute_to_iterator()\n\u001b[1;32m     34\u001b[0m     ds\u001b[39m.\u001b[39m_current_executor \u001b[39m=\u001b[39m executor\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m block_iterator, stats, \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/plan.py:559\u001b[0m, in \u001b[0;36mExecutionPlan.execute_to_iterator\u001b[0;34m(self, allow_clear_input_blocks, force_read)\u001b[0m\n\u001b[1;32m    557\u001b[0m gen \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(block_iter)\n\u001b[1;32m    558\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m     block_iter \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mchain([\u001b[39mnext\u001b[39;49m(gen)], gen)\n\u001b[1;32m    560\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    561\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/legacy_compat.py:61\u001b[0m, in \u001b[0;36mexecute_to_legacy_block_iterator\u001b[0;34m(executor, plan, allow_clear_input_blocks, dataset_uuid)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Same as execute_to_legacy_bundle_iterator but returning blocks and metadata.\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m bundle_iter \u001b[39m=\u001b[39m execute_to_legacy_bundle_iterator(\n\u001b[1;32m     59\u001b[0m     executor, plan, allow_clear_input_blocks, dataset_uuid\n\u001b[1;32m     60\u001b[0m )\n\u001b[0;32m---> 61\u001b[0m \u001b[39mfor\u001b[39;00m bundle \u001b[39min\u001b[39;00m bundle_iter:\n\u001b[1;32m     62\u001b[0m     \u001b[39mfor\u001b[39;00m block, metadata \u001b[39min\u001b[39;00m bundle\u001b[39m.\u001b[39mblocks:\n\u001b[1;32m     63\u001b[0m         \u001b[39myield\u001b[39;00m block, metadata\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/interfaces/executor.py:37\u001b[0m, in \u001b[0;36mOutputIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RefBundle:\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_next()\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor.py:145\u001b[0m, in \u001b[0;36mStreamingExecutor.execute.<locals>.StreamIterator.get_next\u001b[0;34m(self, output_split_idx)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_next\u001b[39m(\u001b[39mself\u001b[39m, output_split_idx: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RefBundle:\n\u001b[1;32m    144\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m         item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_outer\u001b[39m.\u001b[39;49m_output_node\u001b[39m.\u001b[39;49mget_output_blocking(\n\u001b[1;32m    146\u001b[0m             output_split_idx\n\u001b[1;32m    147\u001b[0m         )\n\u001b[1;32m    148\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outer\u001b[39m.\u001b[39m_global_info:\n\u001b[1;32m    149\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outer\u001b[39m.\u001b[39m_global_info\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m, dag\u001b[39m.\u001b[39m_estimated_output_blocks)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor_state.py:287\u001b[0m, in \u001b[0;36mOpState.get_output_blocking\u001b[0;34m(self, output_split_idx)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Check if StreamingExecutor has caught an exception or is done execution.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    288\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finished \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutqueue) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    289\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor.py:212\u001b[0m, in \u001b[0;36mStreamingExecutor.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run the control loop in a helper thread.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[39mResults are returned via the output node's outqueue.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[39m# Run scheduling loop until complete.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scheduling_loop_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_topology) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown:\n\u001b[1;32m    213\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# Propagate it to the result iterator.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor.py:260\u001b[0m, in \u001b[0;36mStreamingExecutor._scheduling_loop_step\u001b[0;34m(self, topology)\u001b[0m\n\u001b[1;32m    255\u001b[0m     logger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mScheduling loop step...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    257\u001b[0m \u001b[39m# Note: calling process_completed_tasks() is expensive since it incurs\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# ray.wait() overhead, so make sure to allow multiple dispatch per call for\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m# greater parallelism.\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m num_errored_blocks \u001b[39m=\u001b[39m process_completed_tasks(\n\u001b[1;32m    261\u001b[0m     topology, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backpressure_policies, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_max_errored_blocks\n\u001b[1;32m    262\u001b[0m )\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_errored_blocks \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    264\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_errored_blocks \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m num_errored_blocks\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor_state.py:477\u001b[0m, in \u001b[0;36mprocess_completed_tasks\u001b[0;34m(topology, backpressure_policies, max_errored_blocks)\u001b[0m\n\u001b[1;32m    471\u001b[0m             error_message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    472\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m Dataset execution will now abort.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m To ignore this exception and continue, set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    474\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m DataContext.max_errored_blocks.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    475\u001b[0m             )\n\u001b[1;32m    476\u001b[0m             logger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39merror(error_message)\n\u001b[0;32m--> 477\u001b[0m             \u001b[39mraise\u001b[39;00m e \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    479\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(task, MetadataOpTask)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/streaming_executor_state.py:444\u001b[0m, in \u001b[0;36mprocess_completed_tasks\u001b[0;34m(topology, backpressure_policies, max_errored_blocks)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(task, DataOpTask):\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         num_blocks_read \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39;49mon_data_ready(\n\u001b[1;32m    445\u001b[0m             max_blocks_to_read_per_op\u001b[39m.\u001b[39;49mget(state, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    446\u001b[0m         )\n\u001b[1;32m    447\u001b[0m         \u001b[39mif\u001b[39;00m state \u001b[39min\u001b[39;00m max_blocks_to_read_per_op:\n\u001b[1;32m    448\u001b[0m             max_blocks_to_read_per_op[state] \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m num_blocks_read\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/interfaces/physical_operator.py:102\u001b[0m, in \u001b[0;36mDataOpTask.on_data_ready\u001b[0;34m(self, max_blocks_to_read)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    101\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_done_callback(ex)\n\u001b[0;32m--> 102\u001b[0m         \u001b[39mraise\u001b[39;00m ex \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_ready_callback(\n\u001b[1;32m    104\u001b[0m     RefBundle([(block_ref, meta)], owns_blocks\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    105\u001b[0m )\n\u001b[1;32m    106\u001b[0m num_blocks_read \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/interfaces/physical_operator.py:98\u001b[0m, in \u001b[0;36mDataOpTask.on_data_ready\u001b[0;34m(self, max_blocks_to_read)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     \u001b[39m# The generator should always yield 2 values (block and metadata)\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[39m# each time. If we get a StopIteration here, it means an error\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[39m# TODO(hchen): Ray Core should have a better interface for\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# detecting and obtaining the exception.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m         ray\u001b[39m.\u001b[39;49mget(block_ref)\n\u001b[1;32m     99\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mAbove ray.get should raise an exception.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:22\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mauto_init_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     21\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 22\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/_private/worker.py:2624\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2622\u001b[0m     worker\u001b[39m.\u001b[39mcore_worker\u001b[39m.\u001b[39mdump_object_store_memory_usage()\n\u001b[1;32m   2623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayTaskError):\n\u001b[0;32m-> 2624\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   2625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2626\u001b[0m     \u001b[39mraise\u001b[39;00m value\n",
      "\u001b[0;31mRayTaskError(OSError)\u001b[0m: \u001b[36mray::ReadCustomJSON->SplitBlocks(104)()\u001b[39m (pid=52226, ip=127.0.0.1)\n    for b_out in map_transformer.apply_transform(iter(blocks), ctx):\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 430, in __call__\n    for block in blocks:\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 371, in __call__\n    for data in iter:\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 232, in __call__\n    yield from self._block_fn(input, ctx)\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/planner/plan_read_op.py\", line 82, in do_read\n    yield from read_task()\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/datasource/datasource.py\", line 237, in __call__\n    yield from result\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 308, in read_task_fn\n    yield from read_files(read_paths)\n  File \"/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 279, in read_files\n    for block in read_stream(f, read_path):\n  File \"/Users/schwobel/Documents/code/fmeval_hackathon/fmeval/src/fmeval/data_loaders/json_data_loader.py\", line 95, in _read_stream\n    json_lines_strings = f.readall().decode().strip().split(\"\\n\")\n  File \"pyarrow/io.pxi\", line 514, in pyarrow.lib.NativeFile.readall\n  File \"pyarrow/io.pxi\", line 392, in pyarrow.lib.NativeFile.read\n  File \"pyarrow/io.pxi\", line 409, in pyarrow.lib.NativeFile.read\n  File \"pyarrow/error.pxi\", line 154, in pyarrow.lib.pyarrow_internal_check_status\n  File \"pyarrow/error.pxi\", line 91, in pyarrow.lib.check_status\nOSError: AWS Error NETWORK_CONNECTION during GetObject operation: curlCode: 6, Couldn't resolve host name"
     ]
    }
   ],
   "source": [
    "results_qa_base = run_eval(model_runner_base, model_id_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  return transform_pyarrow.concat(tables)\n",
      "2024-03-21 15:35:43,026\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "2024-03-21 15:35:43,027\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:35:43,028\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "                                                                                                                  \n",
      "\u001b[A\n",
      "\u001b[A2024-03-21 15:35:43,104\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_prompt_column)]\n",
      "2024-03-21 15:35:43,105\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:35:43,106\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:35:43,254\tWARNING util.py:546 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-03-21 15:35:43,259\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[Map(ModelRunnerWrapper)]\n",
      "2024-03-21 15:35:43,260\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:35:43,261\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:35:43,306\tINFO actor_pool_map_operator.py:114 -- Map(ModelRunnerWrapper): Waiting for 9 pool actors to start...\n",
      "2024-03-21 15:36:00,423\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_eval_scores)]\n",
      "2024-03-21 15:36:00,424\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:36:00,424\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:36:00,507\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:36:00,508\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:36:00,508\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:36:00,588\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:36:00,588\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:36:00,589\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:36:00,666\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:36:00,666\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:36:00,667\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:36:00,747\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:36:00,748\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:36:00,748\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:36:00,822\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:36:00,823\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:36:00,823\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:36:00,904\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-21 15:36:00,905\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:36:00,905\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:36:00,981\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-21 15:36:00,982\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:36:00,982\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:   0%|          | 0/45 [00:00<?, ?it/s]/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "2024-03-21 15:37:36,973\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=104 for stage ReadCustomJSON to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-03-21 15:37:36,975\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 104, each read task output is split into 104 smaller blocks.\n",
      "2024-03-21 15:37:36,976\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCustomJSON] -> LimitOperator[limit=100000]\n",
      "2024-03-21 15:37:36,976\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:37:36,977\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "Running: 1.0/10.0 CPU, 0.0/0.0 GPU, 132.87 MiB/512.0 MiB object_store_memory:  99%|█████████▊| 66/67 [01:18<00:01,  1.32s/it]/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  return transform_pyarrow.concat(tables)\n",
      "2024-03-21 15:38:55,695\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "2024-03-21 15:38:55,696\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:38:55,696\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "                                                                                                                  \n",
      "\u001b[A\n",
      "\u001b[A2024-03-21 15:38:55,760\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_prompt_column)]\n",
      "2024-03-21 15:38:55,761\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:38:55,761\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:38:55,928\tWARNING util.py:546 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-03-21 15:38:55,933\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[Map(ModelRunnerWrapper)]\n",
      "2024-03-21 15:38:55,933\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:38:55,934\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:38:56,045\tINFO actor_pool_map_operator.py:114 -- Map(ModelRunnerWrapper): Waiting for 9 pool actors to start...\n",
      "2024-03-21 15:39:12,001\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_eval_scores)]\n",
      "2024-03-21 15:39:12,001\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:12,002\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:39:12,081\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:12,082\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:12,082\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:12,162\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:12,163\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:12,163\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:12,255\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:12,256\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:12,256\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:12,358\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:12,359\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:12,360\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:12,437\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:12,437\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:12,438\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:12,512\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-21 15:39:12,513\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:12,513\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:39:12,593\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-21 15:39:12,593\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:12,594\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:   0%|          | 0/45 [00:00<?, ?it/s]/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  return transform_pyarrow.concat(tables)\n",
      "2024-03-21 15:39:24,599\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "2024-03-21 15:39:24,600\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:24,601\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "                                                                                                                  \n",
      "\u001b[A\n",
      "\u001b[A2024-03-21 15:39:24,670\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_prompt_column)]\n",
      "2024-03-21 15:39:24,671\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:24,671\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:39:24,782\tWARNING util.py:546 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-03-21 15:39:24,791\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[Map(ModelRunnerWrapper)]\n",
      "2024-03-21 15:39:24,792\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:24,793\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:39:24,842\tINFO actor_pool_map_operator.py:114 -- Map(ModelRunnerWrapper): Waiting for 9 pool actors to start...\n",
      "2024-03-21 15:39:43,615\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(_generate_eval_scores)]\n",
      "2024-03-21 15:39:43,616\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:43,616\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:39:44,549\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:44,550\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:44,550\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:44,641\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:44,642\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:44,642\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:44,723\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:44,723\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:44,724\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:44,801\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:44,802\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:44,802\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:44,881\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-03-21 15:39:44,881\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:44,882\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "                                                                                                                 \n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A2024-03-21 15:39:44,964\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-21 15:39:44,964\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:44,965\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-03-21 15:39:45,039\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-03-21 15:39:45,040\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-03-21 15:39:45,040\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:   0%|          | 0/45 [00:00<?, ?it/s]/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n",
      "                                                                                                                 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(Map(_generate_prompt_column) pid=47068)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47068)\u001b[0m   if isinstance(items[0], TensorArrayElement):                           \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47068)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47068)\u001b[0m   return items[0]                                                        \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47068)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47068)\u001b[0m   if isinstance(items[0], TensorArrayElement):                           \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47068)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47068)\u001b[0m   return items[0]                                                        \n",
      "Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:  89%|████████▉ | 40/45 [00:00<00:00, 216.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=49047)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "\u001b[36m(_MapWorker pid=49047)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Users/schwobel/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=49050)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47072)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47072)\u001b[0m   if isinstance(items[0], TensorArrayElement):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47072)\u001b[0m   return items[0]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=49049)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=49047)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47064)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47064)\u001b[0m   if isinstance(items[0], TensorArrayElement):                 \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47064)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47064)\u001b[0m   return items[0]                                              \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47064)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47064)\u001b[0m   if isinstance(items[0], TensorArrayElement):                         \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47064)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47064)\u001b[0m   return items[0]                                                        \n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=49049)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:  22%|██▏       | 10/45 [00:00<00:00, 166.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=49500)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=49500)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Users/schwobel/Library/Application Support/sagemaker/config.yaml\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=49502)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47069)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47069)\u001b[0m   if isinstance(items[0], TensorArrayElement):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47069)\u001b[0m   return items[0]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=49502)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\n",
      "\u001b[36m(_MapWorker pid=49507)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "Running: 2.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:  22%|██▏       | 10/45 [00:01<00:05,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(Map(<lambda>) pid=49564)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(<lambda>) pid=49564)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Users/schwobel/Library/Application Support/sagemaker/config.yaml\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(Map(_generate_prompt_column) pid=47071)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47071)\u001b[0m   if isinstance(items[0], TensorArrayElement):                           \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47071)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47071)\u001b[0m   return items[0]                                                        \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47071)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47071)\u001b[0m   if isinstance(items[0], TensorArrayElement):                           \n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47071)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=47071)\u001b[0m   return items[0]                                                        \n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=49501)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory: 100%|██████████| 45/45 [00:00<00:00, 645.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=49604)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=49604)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /Users/schwobel/Library/Application Support/sagemaker/config.yaml\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=49600)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=49564)\u001b[0m /Users/schwobel/anaconda3/envs/fmeval_env/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=49564)\u001b[0m   if isinstance(items[0], TensorArrayElement):\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(Map(_generate_prompt_column) pid=49564)\u001b[0m   return items[0]\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_MapWorker pid=49599)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(MapWorker(Map(ModelRunnerWrapper)) pid=49599)\u001b[0m Unable to fetch log_probability from model response: Extractor cannot extract log_probability as log_probability_jmespath_expression is not provided\n",
      "\u001b[36m(_MapWorker pid=49601)\u001b[0m Using model 'huggingface-llm-falcon-7b-bf16' with wildcard version identifier '*'. You can pin to version '2.2.2' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "Running: 0.0/10.0 CPU, 0.0/0.0 GPU, 0.0 MiB/512.0 MiB object_store_memory:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results_qa_instruct = run_eval(model_runner_instruct, model_id_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(files):\n",
    "    accuracy_results = []\n",
    "    for file in files:\n",
    "        accuracy_file = os.path.join(file, 'aggregate_accuracy.json')\n",
    "        with open(accuracy_file, 'r') as f:\n",
    "            res = json.load(f)\n",
    "            for accuracy_eval in res['accuracy']:\n",
    "                for accuracy_scores in accuracy_eval[\"dataset_scores\"]:\n",
    "                    accuracy_results.append(\n",
    "                        {'model': model, 'evaluation': 'accuracy', 'dataset': accuracy_eval[\"dataset_name\"],\n",
    "                         'metric': accuracy_scores[\"name\"], 'value': accuracy_scores[\"value\"]})\n",
    "        \n",
    "    accuracy_results_df = pd.DataFrame(accuracy_results)\n",
    "    return accuracy_results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_radar(results_df, dataset, metric_names, evaluation, version, openbook=False, print_title=False):\n",
    "    # aggregate 3 datasets into 1 by taking mean across datasets\n",
    "    if dataset == 'all':\n",
    "       mean_across_datasets = results_df.drop('evaluation', axis=1).groupby(['model', 'metric']).describe()['value']['mean']\n",
    "       results_df = pd.DataFrame(mean_across_datasets).reset_index().rename({'mean':'value'}, axis=1)\n",
    "    # plot a single dataset\n",
    "    else:\n",
    "        results_df = results_df[results_df['dataset'] == dataset]\n",
    "\n",
    "    results_df.replace(metric_names, inplace=True)    \n",
    "    # to guarantee the order is the same always\n",
    "    order_dict = {}\n",
    "    for i, name in enumerate(metric_names.values()): \n",
    "        order_dict[name] = i\n",
    "    results_df.sort_values(by=['metric'], key=lambda x: x.map(order_dict), inplace=True)\n",
    "    \n",
    "    fig = px.line_polar(results_df, r='value', theta='metric', color='model', line_close=True) \n",
    "                        # color_discrete_map = {'llama-2-7B': colors.qualitative.Plotly[0], 'llama-2-70B': colors.qualitative.Plotly[1], 'falcon-7B': colors.qualitative.Plotly[2],\n",
    "                        #                       'chatgpt-3-5': colors.qualitative.Plotly[3], 'falcon-40B': colors.qualitative.Plotly[4], 'claude-2': colors.qualitative.Plotly[5], \n",
    "                        #                       'chatgpt-4': colors.qualitative.Plotly[6]})\n",
    "    \n",
    "    xlim = 1\n",
    "    # xlim = 0.6 if 'toxicity' in evaluation else 1\n",
    "    fig.update_layout(\n",
    "        polar=dict(\n",
    "            radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, xlim],\n",
    "            )),\n",
    "        # font_size=25,\n",
    "        # font_family=\"Times New Roman\",\n",
    "        # showlegend=False,\n",
    "        # margin=dict(l=20, r=0, t=100, b=80)\n",
    "    )\n",
    "    # if dataset in ['natural_questions', 'real_toxicity_prompts_challenging'] or (dataset=='all' and 'toxicity' in evaluation) or openbook:\n",
    "    #     # show + move legend\n",
    "    #     fig.update_layout(\n",
    "    #         showlegend=True,\n",
    "    #             legend=dict(\n",
    "    #             yanchor=\"top\",\n",
    "    #             y=0.99,\n",
    "    #             xanchor=\"right\",\n",
    "    #             x=1.6\n",
    "    #         ))\n",
    "    \n",
    "    if print_title:\n",
    "        title = dataset\n",
    "        fig.update_layout(\n",
    "            title=dict(text=title, font=dict(size=30), automargin=True, yref='container') #'paper')\n",
    "        )\n",
    "    \n",
    "    directory = \"plots/radarplots_openbook\" if openbook else \"plots/radarplots\"\n",
    "    plot_path = f\"{directory}/radar_{evaluation}_{dataset}_v={version}\"\n",
    "    if openbook:\n",
    "        plot_path += '_openbook'\n",
    "    fig.write_image(f\"{plot_path}.pdf\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmeval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
