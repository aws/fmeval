[{"eval_name": "qa_accuracy", "dataset_name": "boolq", "dataset_scores": [{"name": "f1_score", "value": 0.4, "error": null}, {"name": "exact_match_score", "value": 0.4, "error": null}, {"name": "quasi_exact_match_score", "value": 0.4, "error": null}, {"name": "precision_over_words", "value": 0.4, "error": null}, {"name": "recall_over_words", "value": 0.4, "error": null}], "prompt_template": "Respond to the following question. Valid answers are \"True\" or \"False\". $model_input", "category_scores": null, "output_path": "/tmp/eval_results/qa_accuracy_boolq.jsonl", "error": null}, {"eval_name": "qa_accuracy", "dataset_name": "trivia_qa", "dataset_scores": [{"name": "f1_score", "value": 0.1711064425770308, "error": null}, {"name": "exact_match_score", "value": 0.0, "error": null}, {"name": "quasi_exact_match_score", "value": 0.0, "error": null}, {"name": "precision_over_words", "value": 0.11117566643882433, "error": null}, {"name": "recall_over_words", "value": 0.5833333333333333, "error": null}], "prompt_template": "Respond to the following question with a short answer: $model_input", "category_scores": null, "output_path": "/tmp/eval_results/qa_accuracy_trivia_qa.jsonl", "error": null}, {"eval_name": "qa_accuracy", "dataset_name": "natural_questions", "dataset_scores": [{"name": "f1_score", "value": 0.2533333333333333, "error": null}, {"name": "exact_match_score", "value": 0.2, "error": null}, {"name": "quasi_exact_match_score", "value": 0.2, "error": null}, {"name": "precision_over_words", "value": 0.24, "error": null}, {"name": "recall_over_words", "value": 0.27999999999999997, "error": null}], "prompt_template": "Respond to the following question with a short answer: $model_input", "category_scores": null, "output_path": "/tmp/eval_results/qa_accuracy_natural_questions.jsonl", "error": null}]