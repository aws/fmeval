[{"eval_name": "qa_accuracy", "dataset_name": "boolq", "dataset_scores": [{"name": "f1_score", "value": 0.018547378547378545, "error": null}, {"name": "exact_match_score", "value": 0.0, "error": null}, {"name": "quasi_exact_match_score", "value": 0.0, "error": null}, {"name": "precision_over_words", "value": 0.009447509170843717, "error": null}, {"name": "recall_over_words", "value": 0.6, "error": null}], "prompt_template": "Respond to the following question. Valid answers are \"True\" or \"False\". $model_input", "category_scores": null, "output_path": "/tmp/eval_results/qa_accuracy_boolq.jsonl", "error": null}, {"eval_name": "qa_accuracy", "dataset_name": "trivia_qa", "dataset_scores": [{"name": "f1_score", "value": 0.09044436644436646, "error": null}, {"name": "exact_match_score", "value": 0.0, "error": null}, {"name": "quasi_exact_match_score", "value": 0.0, "error": null}, {"name": "precision_over_words", "value": 0.04937388761759472, "error": null}, {"name": "recall_over_words", "value": 0.7333333333333333, "error": null}], "prompt_template": "Respond to the following question with a short answer: $model_input", "category_scores": null, "output_path": "/tmp/eval_results/qa_accuracy_trivia_qa.jsonl", "error": null}, {"eval_name": "qa_accuracy", "dataset_name": "natural_questions", "dataset_scores": [{"name": "f1_score", "value": 0.061217799576599806, "error": null}, {"name": "exact_match_score", "value": 0.0, "error": null}, {"name": "quasi_exact_match_score", "value": 0.0, "error": null}, {"name": "precision_over_words", "value": 0.03466195334659837, "error": null}, {"name": "recall_over_words", "value": 0.52, "error": null}], "prompt_template": "Respond to the following question with a short answer: $model_input", "category_scores": null, "output_path": "/tmp/eval_results/qa_accuracy_natural_questions.jsonl", "error": null}]
