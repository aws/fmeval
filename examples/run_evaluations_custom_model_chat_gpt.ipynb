{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T22:25:12.260652Z",
     "start_time": "2023-10-10T22:25:04.852238Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/kvasist/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from fmeval.model_runners.model_runner import ModelRunner\n",
    "from fmeval.fmeval import get_eval_algorithm\n",
    "from fmeval.eval_algorithms.factual_knowledge import FactualKnowledgeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T22:25:17.603116Z",
     "start_time": "2023-10-10T22:25:17.580427Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create ChatGPT Custom ModelRunner\n",
    "@dataclass\n",
    "class ChatGPTModelConfig:\n",
    "\ttemperature: float\n",
    "\ttop_p: float\n",
    "\tmax_tokens: int\n",
    "\tapi_key: str\n",
    "\n",
    "\n",
    "class ChatGPTModelRunner(ModelRunner):\n",
    "\turl = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "\tdef __init__(self, model_config: ChatGPTModelConfig):\n",
    "\t\tself.config = model_config\n",
    "\n",
    "\tdef predict(self, prompt: str) -> Tuple[Optional[str], Optional[float]]:\n",
    "\t\tpayload = json.dumps({\n",
    "\t\t\t\"model\": \"gpt-3.5-turbo\",\n",
    "\t\t\t\"messages\": [\n",
    "\t\t\t\t {\n",
    "\t\t\t\t\t \"role\": \"user\",\n",
    "\t\t\t\t\t \"content\": prompt\n",
    "\t\t\t\t }\n",
    "\t\t\t],\n",
    "\t\t\t\"temperature\": self.config.temperature,\n",
    "\t\t\t\"top_p\": self.config.top_p,\n",
    "\t\t\t\"n\": 1,\n",
    "\t\t\t\"stream\": False,\n",
    "\t\t\t\"max_tokens\": self.config.max_tokens,\n",
    "\t\t\t\"presence_penalty\": 0,\n",
    "\t\t\t\"frequency_penalty\": 0\n",
    "\t\t})\n",
    "\t\theaders = {\n",
    "\t\t\t 'Content-Type': 'application/json',\n",
    "\t\t\t 'Accept': 'application/json',\n",
    "\t\t\t 'Authorization': self.config.api_key\n",
    "\t\t}\n",
    "\n",
    "\t\tresponse = requests.request(\"POST\", self.url, headers=headers, data=payload)\n",
    "\n",
    "\t\treturn json.loads(response.text)[\"choices\"][0][\"message\"][\"content\"], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T22:25:21.545789Z",
     "start_time": "2023-10-10T22:25:19.421401Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('London is the capital of England.', None)\n"
     ]
    }
   ],
   "source": [
    "# Validate Custom Model Runner\n",
    "# Note: Don't forget to include your api_key\n",
    "config = ChatGPTModelConfig(\n",
    "\tapi_key='',\n",
    "\ttemperature=1.0,\n",
    "\ttop_p=1.0,\n",
    "\tmax_tokens=250\n",
    ")\n",
    "model_runner = ChatGPTModelRunner(config)\n",
    "print(model_runner.predict(\"London is the capital of?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T22:25:24.350013Z",
     "start_time": "2023-10-10T22:25:24.345135Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate factual_knowledge\n",
    "eval_algorithm_config = FactualKnowledgeConfig(\"<OR>\")\n",
    "eval_algo = get_eval_algorithm(\"factual_knowledge\")(eval_algorithm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T22:25:28.791387Z",
     "start_time": "2023-10-10T22:25:26.769143Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London is the capital of England and the United Kingdom.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[EvalScore(name='factual_knowledge', value=1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate your custom sample\n",
    "model_output = model_runner.predict(\"London is the capital of?\")[0]\n",
    "print(model_output)\n",
    "eval_algo.evaluate_sample(target_output=\"UK<OR>England<OR>United Kingdom\", model_output=model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T22:32:30.591437Z",
     "start_time": "2023-10-10T22:25:41.326234Z"
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 04:16:04,625\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2023-10-11 04:16:05,812\tINFO read_api.py:374 -- To satisfy the requested parallelism of 20, each read task output will be split into 20 smaller blocks.\n",
      "2023-10-11 04:16:06,447\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCustomJSON->SplitBlocks(20)] -> ActorPoolMapOperator[MapBatches(process_batch)->Map(ModelRunnerWrapper)]\n",
      "2023-10-11 04:16:06,447\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-10-11 04:16:06,448\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2023-10-11 04:16:06,483\tINFO actor_pool_map_operator.py:117 -- MapBatches(process_batch)->Map(ModelRunnerWrapper): Waiting for 9 pool actors to start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(_MapWorker pid=11603)\u001B[0m sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "\u001B[2m\u001B[36m(_MapWorker pid=11603)\u001B[0m sagemaker.config INFO - Not applying SDK defaults from location: /Users/kvasist/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 04:17:43,357\tINFO dataset.py:2180 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2023-10-11 04:17:43,359\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(process_batch)] -> AllToAllOperator[Aggregate]\n",
      "2023-10-11 04:17:43,360\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-10-11 04:17:43,360\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(MapBatches(process_batch) pid=11591)\u001B[0m sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\u001B[32m [repeated 18x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001B[0m\n",
      "\u001B[2m\u001B[36m(MapBatches(process_batch) pid=11591)\u001B[0m sagemaker.config INFO - Not applying SDK defaults from location: /Users/kvasist/Library/Application Support/sagemaker/config.yaml\u001B[32m [repeated 18x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 04:17:44,109\tWARNING plan.py:567 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "2023-10-11 04:17:44,111\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(process_batch)] -> LimitOperator[limit=1]\n",
      "2023-10-11 04:17:44,112\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-10-11 04:17:44,112\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 04:17:45,298\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(process_batch)] -> AllToAllOperator[Aggregate] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "2023-10-11 04:17:45,298\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-10-11 04:17:45,299\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 04:17:46,112\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(process_batch)] -> AllToAllOperator[Aggregate]\n",
      "2023-10-11 04:17:46,112\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-10-11 04:17:46,112\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 04:17:46,283\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(process_batch)->Map(<lambda>)]\n",
      "2023-10-11 04:17:46,284\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-10-11 04:17:46,284\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 04:17:46,337\tINFO streaming_executor.py:92 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(process_batch)->Map(<lambda>)]\n",
      "2023-10-11 04:17:46,337\tINFO streaming_executor.py:93 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-10-11 04:17:46,337\tINFO streaming_executor.py:95 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model with amazon-fmeval built-in dataset\n",
    "from fmeval.data_loaders.data_config import DataConfig\n",
    "dataset_config = DataConfig(\n",
    "        dataset_name=\"TREX\",\n",
    "        dataset_uri=\"trex_sample.jsonl\",\n",
    "        dataset_mime_type=\"application/jsonlines\",\n",
    "        model_input_location=\"question\",\n",
    "        target_output_location=\"answers\",\n",
    "        category_location=\"knowledge_category\",\n",
    "    )\n",
    "\n",
    "# Evaluate model with amazon-fmeval built-in dataset\n",
    "eval_outputs = eval_algo.evaluate(model=model_runner, dataset_config=dataset_config, prompt_template=\"$feature\", save=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T22:32:30.602824Z",
     "start_time": "2023-10-10T22:32:30.596839Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EvalOutput(eval_name='factual_knowledge', dataset_name='TREX', dataset_scores=[EvalScore(name='factual_knowledge', value=0.7611940298507462)], prompt_template='$feature', category_scores=[CategoryScore(name='Capitals', scores=[EvalScore(name='factual_knowledge', value=0.8)]), CategoryScore(name='Subsidiary', scores=[EvalScore(name='factual_knowledge', value=0.7227722772277227)])], output_path='/tmp/eval_results/')]\n"
     ]
    }
   ],
   "source": [
    "# Show Evaluation outputs\n",
    "print(eval_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T22:32:30.662696Z",
     "start_time": "2023-10-10T22:32:30.607337Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model_input\": \"Lichinga is the capital of\", \"model_output\": \"Niassa province in Mozambique.\", \"target_output\": \"Niassa province<OR>Niassa Province\", \"category\": \"Capitals\", \"prompt\": \"Lichinga is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 1}]}\n",
      "\n",
      "{\"model_input\": \"Thimphu is the capital of\", \"model_output\": \"Thimphu is the capital of Bhutan.\", \"target_output\": \"Thimphu District<OR>Bhutan\", \"category\": \"Capitals\", \"prompt\": \"Thimphu is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 1}]}\n",
      "\n",
      "{\"model_input\": \"Vientiane is the capital of\", \"model_output\": \"Laos.\", \"target_output\": \"Laotian<OR>Laos\", \"category\": \"Capitals\", \"prompt\": \"Vientiane is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 1}]}\n",
      "\n",
      "{\"model_input\": \"Sapporo is the capital of\", \"model_output\": \"Hokkaido, Japan.\", \"target_output\": \"Hokkaido<OR>Hokkaido Prefecture<OR>Hokkaid\\u014d<OR>Ishikari\", \"category\": \"Capitals\", \"prompt\": \"Sapporo is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 1}]}\n",
      "\n",
      "{\"model_input\": \"Bern is the capital of\", \"model_output\": \"Switzerland.\", \"target_output\": \"Switzerland<OR>Swiss\", \"category\": \"Capitals\", \"prompt\": \"Bern is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 1}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show first five rows of saved output\n",
    "with open('/tmp/eval_results/factual_knowledge_TREX.jsonl') as f:\n",
    "\tlines = [next(f) for _ in range(5)]\n",
    "for line in lines:\n",
    "\tprint(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
