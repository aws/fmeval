{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8dae933-0b5f-4c6f-b9fc-145e467071b9",
   "metadata": {},
   "source": [
    "## Evaluating a model on factual knowledge using pre-existing model outputs\n",
    "\n",
    "In this example, we use a JumpStart endpoint to run inference on an entire dataset and store these results before running a factual knowledge evaluation. This example mimics use cases where the dataset used for the evaluation already contains the model outputs.\n",
    "\n",
    "Environment:\n",
    "- Base Python 3.0 kernel\n",
    "- Studio Notebook instance type: ml.g4dn.xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa600089-3179-4443-8227-48b9b3f56f16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aaaf7d-da6a-40d5-81ce-582a84f7f5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the fmeval package\n",
    "\n",
    "!rm -Rf ~/.cache/pip/*\n",
    "!pip3 install fmeval --upgrade-strategy only-if-needed --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f920ab-e925-4b96-9cbc-50b36b6af3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Check that the dataset file to be used by the evaluation is present\n",
    "if not glob.glob(\"trex_sample.jsonl\"):\n",
    "    print(\"ERROR - please make sure the file, trex_sample.jsonl, exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a8297-ce56-4793-8aca-095382e76175",
   "metadata": {},
   "source": [
    "### JumpStart endpoint creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc561a07-56ab-40ed-ac88-faa76c73eef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "\n",
    "# Uncomment the line below and fill in the endpoint name if you have an existing endpoint.\n",
    "# endpoint_name = \"Enter your endpoint name here\"\n",
    "\n",
    "\n",
    "# Uncomment the lines below to deploy a new endpoint.\n",
    "# model_id = \"huggingface-llm-falcon-7b-instruct-bf16\"\n",
    "# my_model = JumpStartModel(model_id=model_id)\n",
    "# predictor = my_model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81acb9f-4bc6-4b54-9c42-c04fcc7b31c6",
   "metadata": {},
   "source": [
    "#### Sample endpoint invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b5f20-5afa-4b63-b6dd-a9388e5b9060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Tell me about Amazon SageMaker.\"\n",
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.8,\n",
    "        \"max_new_tokens\": 1024,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae4fa8-9444-42d1-8dfe-9713f4b26564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "content_type = \"application/json\"\n",
    "runtime = boto3.client(\"sagemaker-runtime\")\n",
    "    \n",
    "try:\n",
    "    # Invoke the existing endpoint\n",
    "    print(f\"Utilizing invoke_endpoint API call for existing endpoint: {endpoint_name}\")\n",
    "    response = runtime.invoke_endpoint(EndpointName=endpoint_name, Body=json.dumps(payload), ContentType=content_type)\n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    print(result[0]['generated_text'])\n",
    "    \n",
    "except NameError:\n",
    "    # Invoke the predictor that we created earlier\n",
    "    endpoint_name = predictor.endpoint_name\n",
    "    response = predictor.predict(payload)\n",
    "    print(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9228060-c528-4fc2-adf4-df8e7fe51b83",
   "metadata": {},
   "source": [
    "### Performing model inference on the full dataset\n",
    "\n",
    "Before configuring a factual knowledge evaluation, we will create a new dataset file that contains the same data as the original dataset, but with model outputs added in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60129159-d964-473a-a156-0cfe633d3e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_payload(prompt: str, parameters: dict = {\"do_sample\": True, \"top_p\": 0.9, \"temperature\": 0.8, \"max_new_tokens\": 32}) -> dict:\n",
    "    \"\"\"\n",
    "    Creates a model invocation payload.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Prompt for the LLM\n",
    "        parameters (dict): Customizable model invocation parameters\n",
    "    \n",
    "    Returns:\n",
    "        Payload to be used when invoking the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(prompt) == 0:\n",
    "        raise ValueError(\"Please provide a non-empty prompt.\")\n",
    "    \n",
    "    return {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": parameters\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed17f1-7466-4a4c-85ea-eebb8e928f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee97a140-f92a-4942-a343-c56eda722d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "input_file = \"trex_sample.jsonl\"\n",
    "output_file = \"trex_sample_with_model_outputs.jsonl\"\n",
    "\n",
    "# For each line in `input_file`, invoke the model using the input from that line,\n",
    "# augment the line with the invocation results, and write the augmented line to `output_file`.\n",
    "with jsonlines.open(input_file) as input_fh, jsonlines.open(output_file, \"w\") as output_fh:\n",
    "    for line in input_fh:\n",
    "        if \"question\" in line:\n",
    "            question = line[\"question\"]\n",
    "            print(f\"Question: {question}\")\n",
    "            payload = create_payload(question)\n",
    "            response = runtime.invoke_endpoint(EndpointName=endpoint_name, Body=json.dumps(payload), ContentType=content_type)\n",
    "            result = json.loads(response['Body'].read().decode())\n",
    "            model_output = result[0]['generated_text']\n",
    "            print(f\"Model output: {model_output}\")\n",
    "            print(\"==============================\")\n",
    "            line[\"model_output\"] = model_output\n",
    "            output_fh.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788d618-db06-42a6-ac13-9785f5269788",
   "metadata": {},
   "source": [
    "### FMEval Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d9e90-81af-403e-83f0-28f6a5ee4a10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fmeval.data_loaders.data_config import DataConfig\n",
    "from fmeval.constants import MIME_TYPE_JSONLINES\n",
    "from fmeval.eval_algorithms.factual_knowledge import FactualKnowledge, FactualKnowledgeConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae741ef1-85f2-4e0f-afc9-017316ba401b",
   "metadata": {},
   "source": [
    "#### Data Config Setup\n",
    "\n",
    "Below, we create a DataConfig for the local dataset file we just created, trex_sample_with_model_outputs.jsonl.\n",
    "- `dataset_name` is just an identifier for your own reference\n",
    "- `dataset_uri` is either a local path to a file or an S3 URI\n",
    "- `dataset_mime_type` is the MIME type of the dataset. Currently, JSON and JSON Lines are supported.\n",
    "- `model_input_location`, `target_output_location`, and `model_output_location` are JMESPath queries used to find the model inputs, target outputs, and model outputs within the dataset. The values that you specify here depend on the structure of the dataset itself. Take a look at trex_sample_with_model_outputs.jsonl to see where \"question\", \"answers\", and \"model_output\" show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7945ed88-581c-4dfb-9ee4-1669467df3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = DataConfig(\n",
    "    dataset_name=\"trex_sample_with_model_outputs\",\n",
    "    dataset_uri=\"trex_sample_with_model_outputs.jsonl\",\n",
    "    dataset_mime_type=MIME_TYPE_JSONLINES,\n",
    "    model_input_location=\"question\",\n",
    "    target_output_location=\"answers\",\n",
    "    model_output_location=\"model_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86721fce-b1dd-4b71-93d2-ed3c405bd28b",
   "metadata": {},
   "source": [
    "### Run Evaluation\n",
    "\n",
    "In other use cases that we showcase in the other example notebooks, we usually pass a model runner and prompt template to the `evaluate` method of our evaluation algorithm. However, since our dataset already contains all of model inference outputs, we only need to pass our dataset config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfacfe4-6cf6-4c46-ac87-4e4ab8c19c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_algo = FactualKnowledge(FactualKnowledgeConfig(target_output_delimiter=\"<OR>\"))\n",
    "eval_output = eval_algo.evaluate(dataset_config=config, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b679c-2fa5-42e9-b090-cd11e3ad62b8",
   "metadata": {},
   "source": [
    "#### Parse Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c5d54-17c5-4805-8840-dd90a264d59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pretty-print the evaluation output (notice the score).\n",
    "import json\n",
    "print(json.dumps(eval_output, default=vars, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e243cf-42e7-46f5-aae3-c9898e3b262c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame to visualize the results\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "# We obtain the path to the results file from \"output_path\" in the cell above\n",
    "with open(\"/tmp/eval_results/factual_knowledge_trex_sample_with_model_outputs.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "df = pd.DataFrame(data)\n",
    "df['eval_algo'] = df['scores'].apply(lambda x: x[0]['name'])\n",
    "df['eval_score'] = df['scores'].apply(lambda x: x[0]['value'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
