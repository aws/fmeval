{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import torch\n",
    "from transformers import GenerationConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from amazon_fmeval.model_runners.model_runner import ModelRunner\n",
    "from amazon_fmeval.eval_algo_mapping import get_eval_algorithm\n",
    "from amazon_fmeval.eval_algorithms.factual_knowledge import FactualKnowledgeConfig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:46:20.494534Z",
     "start_time": "2023-10-11T04:46:15.734465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:46:24.909098Z",
     "start_time": "2023-10-11T04:46:20.506421Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiayche/.virtualenvs/fmeval/lib/python3.11/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n\\nThe answer is yes.\\n\\nThe city is the capital', -5.30952787399292)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class HFModelConfig:\n",
    "\tmodel_name: str\n",
    "\tgeneration_config: GenerationConfig\n",
    "\tnormalize_probabilities: bool = False\n",
    "\tseed: int = 0\n",
    "\tremove_prompt_from_generated_text: bool = True\n",
    "\n",
    "\n",
    "class HuggingFaceCausalLLMModelRunner(ModelRunner):\n",
    "\n",
    "\tdef __init__(self, model_config: HFModelConfig):\n",
    "\t\tself.config = model_config\n",
    "\t\tself.model = AutoModelForCausalLM.from_pretrained(self.config.model_name)\n",
    "\t\tself.tokenizer = AutoTokenizer.from_pretrained(self.config.model_name)\n",
    "\n",
    "\tdef predict(self, prompt: str) -> Tuple[Optional[str], Optional[float]]:\n",
    "\t\tinput_ids = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
    "\t\tgenerations = self.model.generate(\n",
    "\t\t\t**input_ids,\n",
    "\t\t\tmax_new_tokens=self.config.generation_config.max_new_tokens,\n",
    "\t\t\tpad_token_id=self.tokenizer.eos_token_id,\n",
    "\t\t\tgeneration_config=self.config.generation_config,\n",
    "\t\t)\n",
    "\t\tgeneration_contains_input = (\n",
    "\t\t\tinput_ids[\"input_ids\"][0] == generations[0][: input_ids[\"input_ids\"].shape[1]]\n",
    "\t\t).all()\n",
    "\t\tif self.config.remove_prompt_from_generated_text and not generation_contains_input:\n",
    "\t\t\twarnings.warn(\n",
    "\t\t\t\"Your model does not return the prompt as part of its generations. \"\n",
    "\t\t\t\"`remove_prompt_from_generated_text` does nothing.\"\n",
    "\t\t\t)\n",
    "\t\tif self.config.remove_prompt_from_generated_text and generation_contains_input:\n",
    "\t\t\toutput = self.tokenizer.batch_decode(generations[:, input_ids[\"input_ids\"].shape[1]:])[0]\n",
    "\t\telse:\n",
    "\t\t\toutput = self.tokenizer.batch_decode(generations, skip_special_tokens=True)[0]\n",
    "\n",
    "\t\twith torch.inference_mode():\n",
    "\t\t\tinput_ids = self.tokenizer(self.tokenizer.bos_token + prompt, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\t\t\tmodel_output = self.model(input_ids, labels=input_ids)\n",
    "\t\t\tprobability = -model_output[0].item()\n",
    "\n",
    "\t\treturn output, probability\n",
    "\n",
    "\n",
    "# Test with gpt2\n",
    "generation_config = GenerationConfig()\n",
    "model_config = {\"model_name\": \"gpt2\", \"generation_config\": generation_config}\n",
    "hf_config = HFModelConfig(**model_config)\n",
    "model = HuggingFaceCausalLLMModelRunner(model_config=hf_config)\n",
    "print(model.predict(\"London is the capital of?\"))\n",
    "\n",
    "# Test with facebook/bart-large-cnn\n",
    "# generation_config = GenerationConfig(\n",
    "#         max_new_tokens=40,\n",
    "#         do_sample=True,\n",
    "#         top_k=50,\n",
    "#         top_p=0.9,\n",
    "#     )\n",
    "# hf_config = HFModelConfig(model_name=\"facebook/bart-large-cnn\", generation_config=generation_config)\n",
    "# model = HuggingFaceCausalLLMModelRunner(model_config=hf_config)\n",
    "# print(model.predict(\n",
    "#     \"Summarize the following article in 2 sentences: The art metropolis of Berlin inspires locals and visitors with \"\n",
    "#     \"its famous museum landscape and numerous UNESCO World Heritage sites. It is also an international exhibition \"\n",
    "#     \"venue. You will find a selection of current and upcoming exhibitions here.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Evaluate factual_knowledge\n",
    "eval_algorithm_config = FactualKnowledgeConfig(\"<OR>\")\n",
    "eval_algo = get_eval_algorithm(\"factual_knowledge\")(eval_algorithm_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:46:24.909600Z",
     "start_time": "2023-10-11T04:46:24.905207Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The answer is yes.\n",
      "\n",
      "The city is the capital\n"
     ]
    },
    {
     "data": {
      "text/plain": "[EvalScore(name='factual_knowledge', value=0)]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate your custom sample\n",
    "model_output = model.predict(\"London is the capital of?\")[0]\n",
    "print(model_output)\n",
    "eval_algo.evaluate_sample(target_output=\"UK<OR>England<OR>United Kingdom\", model_output=model_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:46:25.339914Z",
     "start_time": "2023-10-11T04:46:24.910825Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom dataset\n",
    "from amazon_fmeval.data_loaders.data_config import DataConfig\n",
    "dataset_config = DataConfig(\n",
    "        dataset_name=\"TREX\",\n",
    "        dataset_uri=\"/Users/xiayche/workplace/amazon-fmeval/src/examples/trex_sample.jsonl\",\n",
    "        dataset_mime_type=\"application/jsonlines\",\n",
    "        model_input_location=\"question\",\n",
    "        target_output_location=\"answers\",\n",
    "        category_location=\"knowledge_category\",\n",
    "    )\n",
    "\n",
    "# Evaluate model with amazon-fmeval built-in dataset\n",
    "eval_outputs = eval_algo.evaluate(model=model, dataset_config=dataset_config, prompt_template=\"$feature\", save=True)\n",
    ";"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-10-11T05:05:48.111561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EvalOutput(eval_name='factual_knowledge', dataset_name='TREX', dataset_scores=[EvalScore(name='factual_knowledge', value=0.05472636815920398)], prompt_template='$feature', category_scores=[CategoryScore(name='Capitals', scores=[EvalScore(name='factual_knowledge', value=0.09)]), CategoryScore(name='Subsidiary', scores=[EvalScore(name='factual_knowledge', value=0.019801980198019802)])], output_path='/tmp/eval_results/')]\n"
     ]
    }
   ],
   "source": [
    "# Show Evaluation outputs\n",
    "print(eval_outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T04:53:43.837901Z",
     "start_time": "2023-10-11T04:53:43.830508Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"model_input\": \"Palembang is the capital of\", \"model_output\": \" the Democratic Republic of Congo, and is home to the largest number\", \"model_log_probability\": -4.059066295623779, \"target_output\": \"South Sumatra<OR>South Sumatera<OR>Srivijaya\", \"category\": \"Capitals\", \"prompt\": \"Palembang is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 0}]}\n",
      "\n",
      "{\"model_input\": \"Alor Setar is the capital of\", \"model_output\": \" the Kingdom of the Seven Kingdoms. It is located in the\", \"model_log_probability\": -5.383638381958008, \"target_output\": \"Kedah\", \"category\": \"Capitals\", \"prompt\": \"Alor Setar is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 0}]}\n",
      "\n",
      "{\"model_input\": \"Manama is the capital of\", \"model_output\": \" the Democratic Republic of Congo, and is home to the largest number of\", \"model_log_probability\": -4.162099361419678, \"target_output\": \"Bahrain\", \"category\": \"Capitals\", \"prompt\": \"Manama is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 0}]}\n",
      "\n",
      "{\"model_input\": \"Lefko\\u015fa is the capital of\", \"model_output\": \" the Kurdish region of northern Iraq.\\n\\nThe Kurdish\", \"model_log_probability\": -5.33738899230957, \"target_output\": \"Cypriot<OR>Cyprus<OR>Turkish Cypriot<OR>Northern Cyprus\", \"category\": \"Capitals\", \"prompt\": \"Lefko\\u015fa is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 0}]}\n",
      "\n",
      "{\"model_input\": \"Dresden is the capital of\", \"model_output\": \" the state of North Dakota, and is home to the largest number\", \"model_log_probability\": -3.531158208847046, \"target_output\": \"Saxon<OR>Saxony\", \"category\": \"Capitals\", \"prompt\": \"Dresden is the capital of\", \"scores\": [{\"name\": \"factual_knowledge\", \"value\": 0}]}\n"
     ]
    }
   ],
   "source": [
    "# Show first five rows of saved output\n",
    "with open('/tmp/eval_results/factual_knowledge_TREX.jsonl') as f:\n",
    "\tlines = [next(f) for _ in range(5)]\n",
    "for line in lines:\n",
    "\tprint(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-10-11T04:53:43.854060Z",
     "start_time": "2023-10-11T04:53:43.836902Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
